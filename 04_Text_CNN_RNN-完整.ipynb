{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习解决NLP监督任务\n",
    "\n",
    "![jupyter](./imgs/dl_for_nlp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "random_seed = 100\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据预处理与数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(words):\n",
    "    # 转为小写\n",
    "    words = words.lower()\n",
    "    # 去除标点，保留中英文字符\n",
    "    words = re.sub('[^a-z^0-9^\\u4e00-\\u9fa5]', '', words)\n",
    "    # 将所有数字都转为0\n",
    "    words = re.sub('[0-9]', '0', words)\n",
    "    words = ' '.join(words)\n",
    "    # 合并连续的空格\n",
    "    words = re.sub('\\s{2,}', ' ', words)\n",
    "    return words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>肺 炎 疫 情</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>西 方 记 者 挑 事 提 问 w h o 总 干 事 用 事 实 力 挺 中 国 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人 数 终 于 始 呈 下 降 趋 势 这 个 春 节 有 喜 有 忧 但 事 情 终 有 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>抗 病 毒 小 刘 上 线 今 天 有 好 几 个 朋 友 来 问 我 戴 没 戴 口 罩 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>潜 伏 期 传 染 后 期 会 不 会 更 惊 讶 o 最 新 疫 情 地 图 出 炉 这 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                            肺 炎 疫 情      1\n",
       "1  西 方 记 者 挑 事 提 问 w h o 总 干 事 用 事 实 力 挺 中 国 0 0 ...      1\n",
       "2  人 数 终 于 始 呈 下 降 趋 势 这 个 春 节 有 喜 有 忧 但 事 情 终 有 ...      1\n",
       "3  抗 病 毒 小 刘 上 线 今 天 有 好 几 个 朋 友 来 问 我 戴 没 戴 口 罩 ...      1\n",
       "4  潜 伏 期 传 染 后 期 会 不 会 更 惊 讶 o 最 新 疫 情 地 图 出 炉 这 ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df = pd.read_csv('./processed_data/train.csv')\n",
    "raw_train_df['text'] = raw_train_df['text'].apply(preprocess_text)\n",
    "raw_train_df = raw_train_df[raw_train_df['text'] != '']\n",
    "# 过滤掉处理后文本为空的数据\n",
    "raw_train_df[['text', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>星 火 线 上 课 足 不 出 户 同 样 进 步 l 星 火 教 育 呼 市 的 视 频</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中 科 院 病 毒 研 究 所 石 正 丽 老 师 演 讲 追 踪 s a r s 的 源 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>嗯 熊 中 默 就 是 那 个 给 那 位 挂 基 层 辅 警 照 片 暴 平 安 天 门 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>今 天 看 到 两 条 让 我 真 的 笑 笑 出 声 的 为 防 病 毒 出 门 抢 购 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>莫 西 干</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0      星 火 线 上 课 足 不 出 户 同 样 进 步 l 星 火 教 育 呼 市 的 视 频      2\n",
       "1  中 科 院 病 毒 研 究 所 石 正 丽 老 师 演 讲 追 踪 s a r s 的 源 ...      2\n",
       "2  嗯 熊 中 默 就 是 那 个 给 那 位 挂 基 层 辅 警 照 片 暴 平 安 天 门 ...      0\n",
       "3  今 天 看 到 两 条 让 我 真 的 笑 笑 出 声 的 为 防 病 毒 出 门 抢 购 ...      0\n",
       "4                                              莫 西 干      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./processed_data/test.csv')\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text)\n",
    "test_df = test_df[test_df['text'] != '']  # 过滤掉处理后文本为空的数据\n",
    "test_df[['text', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74792, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集与验证集\n",
    "train_df, val_df = train_test_split(\n",
    "    raw_train_df,\n",
    "    test_size=5000,\n",
    "    random_state=1234\n",
    ")\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存划分好的数据集\n",
    "\n",
    "train_df.to_csv('./dataset/train.csv', index=False)\n",
    "val_df.to_csv('./dataset/val.csv', index=False)\n",
    "test_df.to_csv('./dataset/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建TF数据集   \n",
    "\n",
    "TensorFlow全新的数据读取方式：Dataset API入门教程：https://zhuanlan.zhihu.com/p/30751039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74792, 5000, 9998)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取原始数据集\n",
    "train_text, train_label = train_df['text'], train_df['label']\n",
    "val_text, val_label = val_df['text'], val_df['label']\n",
    "test_text, test_label = test_df['text'], test_df['label']\n",
    "len(train_label), len(val_label), len(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Tokenizer是一个分词器，用于文本预处理，序列化，向量化等。  \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer  ｜  \n",
    "默认情况下，将删除所有标点符号，从而将文本转换为以空格分隔的单词序列（单词可能包含’字符，如I’am）,然后将这些序列分为标记列表，并将它们编入索引或向量化。注意0是保留索引，不会分配给任何单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (482620102.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/96/0jnny1gj02j8pgfvb9by368m0000gn/T/ipykernel_78698/482620102.py\"\u001B[0;36m, line \u001B[0;32m16\u001B[0m\n\u001B[0;31m    oov_token=None\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    # 根据单词频率排序，保留前num_words个单词，即仅保留最常见的num_words-1个单词\n",
    "    num_words=None,\n",
    "    # 一个用于过滤的正则表达式的字符串，这个过滤器作用在每个元素上，默认过滤除‘`’字符外的所有标点符号，制表符和换行符\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    # 标记是否将文本转换为小写\n",
    "    lower=True,\n",
    "    # 分词分隔符，前面已经处理成用空格分割了\n",
    "    split=' ',\n",
    "    # 是否进行字符级别的分词, 前面已经分好了\n",
    "    char_level=False,\n",
    "    # 指定out of vocabulary词, 将被添加到word_index中，\n",
    "    # 并用于在text_to_sequence调用期间替换词汇外的单词，即用来补充原文本中没有的词。\n",
    "    oov_token=None\n",
    ")\n",
    "\n",
    "# 用训练数据的文本训练tokenizer\n",
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[715], [11], [51], [1300], [878], [600], [512], [102], [266], [30], [2], [120], [584], [20], [], [8], [35], [995], [171], [62], [9], [1102], [216], [221], [16], [1213], [1077], [18], [], [1], [], [1], [51], [2], [120], [3], [20], []]\n"
     ]
    }
   ],
   "source": [
    "text = '写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。'\n",
    "# 将文本数据转化为对应的id序列\n",
    "tokens = tokenizer.texts_to_sequences(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/tokenizer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存tokenzier用于预测\n",
    "tokenizer_save_path = './model/tokenizer.pkl'\n",
    "joblib.dump(tokenizer, tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf dataset\n",
    "官方API： https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "其他：https://www.huaweicloud.com/articles/5fcbf05e61828f8e6eeced07ccedc3c6.html\n",
    "\n",
    "- from_tensor_slices: 用于创建dataset,其元素是给定张量的切片的元素。\n",
    "- shuffle: 随机打乱此数据集的样本。从data数据集中按顺序抽取buffer_size个样本放在buffer中，然后打乱buffer中的样本。\n",
    "buffer中样本个数不足buffer_size，继续从data数据集中安顺序填充至buffer_size，此时会再次打乱。\n",
    "对于完美的打乱，缓冲区大小需要大于或等于数据集的大小。\n",
    "- batch: 将数据集的样本构造成批数据。\n",
    "- prefetch: 创建一个从该数据集中预先读取元素的数据集。大多数数据集输入管道应该以调用预取结束。这允许在处理当前元素时准备后面的元素。这通常会提高延迟和吞吐量，但代价是使用额外的内存来存储预取元素。\n",
    "\n",
    "pad_sequences是做补齐序列作用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别数量\n",
    "NUM_LABEL = 3\n",
    "# 构造数据集的bacth\n",
    "BATCH_SIZE = 64\n",
    "# 最长序列长度，经前面分析，这里取240\n",
    "MAX_LEN = 240\n",
    "# bacth读取数据的缓存大小\n",
    "BUFFER_SIZE = tf.constant(len(train_text), dtype=tf.int64)\n",
    "\n",
    "\n",
    "def build_tf_dataset(words, label, is_train=False):\n",
    "    # 将前面的tokenzier用于当前文本进行id序列化\n",
    "    sequence = tokenizer.texts_to_sequences(words)\n",
    "    # 把所有序列补齐到最长序列长度，padding方式为在后面补齐\n",
    "    padded_sequence = pad_sequences(sequence, padding='post', maxlen=MAX_LEN)\n",
    "    # 将标签转化为tf的one-hot标签，即 1 -> [0, 1, 0]\n",
    "    label_tensor = tf.convert_to_tensor(\n",
    "        tf.one_hot(label, NUM_LABEL),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    # 将序列化的文本数据与标签在一起制作tf dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (padded_sequence, label_tensor)\n",
    "    )\n",
    "    # 训练阶段\n",
    "    if is_train:\n",
    "        # 训练阶段将数据打乱\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "        # 按照batch_size构造数据集，去掉不能组成batch的多余数据\n",
    "        dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "        # 训练时预先将所有的训练数据加载到内存中\n",
    "        dataset = dataset.prefetch(BUFFER_SIZE)\n",
    "    else:\n",
    "        # 非训练阶段无需打乱数据\n",
    "        dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "        # 预读取一个Batch内容\n",
    "        dataset = dataset.prefetch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 分别构造训练、验证、测试tf数据集\n",
    "train_dataset = build_tf_dataset(train_text, train_label, is_train=True)\n",
    "val_dataset = build_tf_dataset(val_text, val_label, is_train=False)\n",
    "test_dataset = build_tf_dataset(test_text, test_label, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [[ 821  383  204  146   82  570   18    3  287   20  541  487  727   82\n",
      "   256  219   20   46   40   87    5  256   19   82  487  727   82  256\n",
      "   325  325    5    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [ 299  807   58    4  642    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  27   14   16  450  123 1386   72  603 1174  687 1003  101   70   24\n",
      "   281  149    1    1    1    1   21 4570  230  310    1    1    1    1\n",
      "   389  601  180  326  349  810  119  113   42  697  835  143 1015 1006\n",
      "   297 1117    2  114  194    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "\n",
      "labels:  [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型构建与训练\n",
    "### 3. 1加载预训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词典大小，留一个unk字符\n",
    "VOCAB_SIZE = len(tokenizer.index_word) + 1\n",
    "# 词向量大小\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/96/0jnny1gj02j8pgfvb9by368m0000gn/T/ipykernel_98835/1275906462.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0mpretrained_vec_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"./word2vec/sg_ns_100.txt\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;31m# 加载预训练词向量\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpretrained_vec_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/96/0jnny1gj02j8pgfvb9by368m0000gn/T/ipykernel_98835/1275906462.py\u001B[0m in \u001B[0;36mget_embeddings\u001B[0;34m(pretrain_vec_path)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mword_vocab\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword_vectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkey_to_index\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;31m# 随机初始化tokenzier词表大小的向量\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     token_embeddings = np.random.uniform(\n\u001B[0m\u001B[1;32m     14\u001B[0m         \u001B[0;34m-\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 996, in _pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 116, in cmd_step_into\n",
      "    if _is_inside_jupyter_cell(frame, pydb) and not filename.endswith(\"iostream.py\"):\n",
      "  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 209, in _is_inside_jupyter_cell\n",
      "    if is_cell_filename(filename):\n",
      "  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 220, in is_cell_filename\n",
      "    ipython_shell = get_ipython()\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "def get_embeddings(pretrain_vec_path):\n",
    "    # 加载训练好的词向量为KeyedVectors\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(\n",
    "        pretrain_vec_path, binary=False\n",
    "    )\n",
    "    # 取出预训练词向量的词汇表\n",
    "    word_vocab = set(word_vectors.key_to_index.keys())\n",
    "    # 随机初始化tokenzier词表大小的向量\n",
    "    token_embeddings = np.random.uniform(\n",
    "        -0.2,\n",
    "        0.2,\n",
    "        size=(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    )\n",
    "    # 从1开始，0是tokenzier预留的索引\n",
    "    for i in range(1, VOCAB_SIZE):\n",
    "        # 取出tokenzier索引对应的词\n",
    "        word = tokenizer.index_word[i]\n",
    "        # 如果词出现在预训练的词中\n",
    "        if word in word_vocab:\n",
    "            # 就将预训练的词向量赋值给它，替换随机初始化\n",
    "            token_embeddings[i, :] = word_vectors.get_vector(word)\n",
    "    return token_embeddings\n",
    "\n",
    "\n",
    "pretrained_vec_path = \"./word2vec/sg_ns_100.txt\"\n",
    "# 加载预训练词向量\n",
    "embeddings = get_embeddings(pretrained_vec_path)\n",
    "embeddings[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 模型定义\n",
    "\n",
    "![jupyter](./imgs/textcnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3种卷积核的filter size\n",
    "FILTERS = [2, 3, 5]\n",
    "# 卷积核的大小\n",
    "NUM_FILTERS = 128\n",
    "# 全连接层大小\n",
    "DENSE_DIM = 256\n",
    "# 类别数\n",
    "CLASS_NUM = 3\n",
    "# dropout比例\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    630800      input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 100)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    25728       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    38528       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    64128       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          98560       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            771         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 858,515\n",
      "Trainable params: 858,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义一个TextCNN的TF Keras model\n",
    "\n",
    "def build_text_cnn_model():\n",
    "    # 模型输入\n",
    "    inputs = tf.keras.Input(shape=(None,), name='input_data')\n",
    "    # embedding层定义\n",
    "    embed = tf.keras.layers.Embedding(\n",
    "        # 词表大小\n",
    "        input_dim=VOCAB_SIZE,\n",
    "        # 词向量维度\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        # # 加载预训练的词向量\n",
    "        # embeddings_initializer=tf.keras.initializers.Constant(embeddings),\n",
    "        # 词向量是否训练\n",
    "        trainable=True,\n",
    "        # 标记是否用0进行mask标记序列补齐到固定长度\n",
    "        mask_zero=True\n",
    "    )(inputs)\n",
    "    # 在embedding层后接dropout\n",
    "    embed = tf.keras.layers.Dropout(DROPOUT_RATE)(embed)\n",
    "\n",
    "    pool_outputs = []\n",
    "    # 分别对文本进行应用不同filter size的卷积\n",
    "    for filter_size in FILTERS:\n",
    "        conv = tf.keras.layers.Conv1D(\n",
    "            # 卷积核大小\n",
    "            filters=NUM_FILTERS,\n",
    "            # filter size\n",
    "            kernel_size=filter_size,\n",
    "            # same padding\n",
    "            padding='same',\n",
    "            # 激活函数\n",
    "            activation='relu',\n",
    "            # 数据格式，最后一维是通道\n",
    "            data_format='channels_last',\n",
    "            # 标记是否使用bias\n",
    "            use_bias=True\n",
    "        )(embed)\n",
    "        # 卷积后进行max pooling\n",
    "        max_pool = tf.keras.layers.GlobalMaxPooling1D(\n",
    "            data_format='channels_last'\n",
    "        )(conv)\n",
    "        # 将对应filter size大小卷积池化后的结果存到list\n",
    "        pool_outputs.append(max_pool)\n",
    "\n",
    "    # 将不同filter size卷积池化后的结果进行拼接\n",
    "    outputs = tf.keras.layers.concatenate(pool_outputs, axis=-1)\n",
    "    # dense层\n",
    "    outputs = tf.keras.layers.Dense(DENSE_DIM, activation='relu')(outputs)\n",
    "    # 对全连接层进行dropout\n",
    "    outputs = tf.keras.layers.Dropout(DROPOUT_RATE)(outputs)\n",
    "    # 最终的分类层\n",
    "    outputs = tf.keras.layers.Dense(CLASS_NUM, activation='softmax')(outputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "text_cnn_model = build_text_cnn_model()\n",
    "text_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1168/1168 [==============================] - 16s 14ms/step - loss: 0.2464 - accuracy: 0.6117 - val_loss: 0.7698 - val_accuracy: 0.6438\n",
      "Epoch 2/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.2038 - accuracy: 0.6769 - val_loss: 0.7227 - val_accuracy: 0.6612\n",
      "Epoch 3/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.1942 - accuracy: 0.6896 - val_loss: 0.7181 - val_accuracy: 0.6602\n",
      "Epoch 4/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.1885 - accuracy: 0.6973 - val_loss: 0.7432 - val_accuracy: 0.6488\n",
      "Epoch 5/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.1837 - accuracy: 0.7070 - val_loss: 0.7318 - val_accuracy: 0.6556\n",
      "Epoch 6/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.1795 - accuracy: 0.7133 - val_loss: 0.7394 - val_accuracy: 0.6496\n",
      "Epoch 7/10\n",
      "1168/1168 [==============================] - 16s 13ms/step - loss: 0.1750 - accuracy: 0.7202 - val_loss: 0.7240 - val_accuracy: 0.6610\n"
     ]
    }
   ],
   "source": [
    "# 学习率\n",
    "LR = 3e-4\n",
    "# 迭代次数\n",
    "EPOCHS = 10\n",
    "# 早停等待次数\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "\n",
    "# 定义Loss为分类的交叉熵损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "# 定义优化器为Adam优化器\n",
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "\n",
    "# 编译模型\n",
    "text_cnn_model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    # 使用accuracy进行评价\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 添加一个早停的callback,可减少模型过拟合\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    # 通过验证集的accuracy做监控指标，几个epoch该指标不再上升，则早停\n",
    "    monitor='val_accuracy',\n",
    "    # 标记几个epoch该指标不再上升，则早停\n",
    "    patience=EARLY_STOP_PATIENCE,\n",
    "    # 标记是否还原在监控指标中取得最好结果的模型权重\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 样本分布不均衡的解决：通过对不同标签的损失进行加权\n",
    "# 这里标签1的数据最多，降低其权重\n",
    "class_weight = {0: 0.4, 1: 0.2, 2: 0.4}\n",
    "\n",
    "# 模型训练\n",
    "history = text_cnn_model.fit(\n",
    "    # 输入训练数据集\n",
    "    train_dataset,\n",
    "    # 迭代次数\n",
    "    epochs=EPOCHS,\n",
    "    # 回调函数\n",
    "    callbacks=[callback],\n",
    "    # 指定验证集\n",
    "    validation_data=val_dataset,\n",
    "    # 对不同类别进行加权\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7176 - accuracy: 0.6693\n",
      "Test Loss: 0.7176308035850525\n",
      "Test Accuracy: 0.6693338751792908\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上进行评估\n",
    "test_loss, test_acc = text_cnn_model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_' + metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.7995056927204132)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将训练过程进行可视化\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/teacher/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/teacher/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model/text_cnn/assets\n"
     ]
    }
   ],
   "source": [
    "# 保存训练好的模型\n",
    "model_save_path = './model/text_cnn'\n",
    "\n",
    "text_cnn_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13284105, 0.68675524, 0.18040365],\n",
       "       [0.17581712, 0.4248113 , 0.3993716 ],\n",
       "       [0.1540485 , 0.54412735, 0.30182415],\n",
       "       [0.3499045 , 0.31558296, 0.33451253],\n",
       "       [0.38513228, 0.42451873, 0.19034901],\n",
       "       [0.5639943 , 0.3865751 , 0.04943058],\n",
       "       [0.03249473, 0.230097  , 0.73740834],\n",
       "       [0.6131127 , 0.2869413 , 0.09994598],\n",
       "       [0.58062726, 0.273777  , 0.14559576],\n",
       "       [0.11190969, 0.26352182, 0.62456846]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对测试集进行预测，得到每个测试样本的在各个标签的分数\n",
    "predictions = text_cnn_model.predict(test_dataset)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出每个测试样本分数最大的标签作为预测标签\n",
    "preds = np.argmax(predictions, axis=-1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.78      0.60      1796\n",
      "           1       0.83      0.60      0.70      5651\n",
      "           2       0.63      0.74      0.68      2551\n",
      "\n",
      "    accuracy                           0.67      9998\n",
      "   macro avg       0.65      0.71      0.66      9998\n",
      "weighted avg       0.72      0.67      0.68      9998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 查看分类结果\n",
    "result = classification_report(test_label, preds)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型预测\n",
    "\n",
    "训练好的模型如何进行在线预测\n",
    "1. 加载保存好的模型\n",
    "2. 对预测文本进行预处理、tokenizer以及padding\n",
    "3. 输入模型进行预测\n",
    "4. 展示预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    630800      input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 100)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    25728       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    38528       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    64128       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          98560       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            771         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 858,515\n",
      "Trainable params: 858,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 加载训练好的Tokenzier\n",
    "tokenizer_save_path = './model/tokenizer.pkl'\n",
    "tokenizer = joblib.load(tokenizer_save_path)\n",
    "\n",
    "# 加载TextCNN模型\n",
    "model_save_path = './model/text_cnn'\n",
    "text_cnn_model = tf.keras.models.load_model(model_save_path)\n",
    "text_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7622092 , 0.15547498, 0.08231588],\n",
       "       [0.15637168, 0.45522764, 0.3884007 ],\n",
       "       [0.02579996, 0.17541012, 0.7987899 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences = [\n",
    "    \"因为疫情被困家里2个月了，好压抑啊，感觉自己抑郁了！\",\n",
    "    \"我国又一个新冠病毒疫苗获批紧急使用。\",\n",
    "    \"我们在一起，打赢这场仗，抗击新馆疫情，我们在行动！\"]\n",
    "\n",
    "# 预处理文本\n",
    "predict_texts = [preprocess_text(text) for text in predict_sentences]\n",
    "# 进行tokenizer\n",
    "predict_sequences = tokenizer.texts_to_sequences(predict_texts)\n",
    "# 进行padding\n",
    "sequence_padded = pad_sequences(\n",
    "    predict_sequences,\n",
    "    padding='post',\n",
    "    maxlen=MAX_LEN\n",
    ")\n",
    "# 得到预测的Logits\n",
    "predict_logits = text_cnn_model.predict(sequence_padded)\n",
    "predict_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出分数最高的标签\n",
    "predict_results = np.argmax(predict_logits, axis=1)\n",
    "# 还原标签\n",
    "predict_labels = [label - 1 for label in predict_results]\n",
    "predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 因为疫情被困家里2个月了，好压抑啊，感觉自己抑郁了！\n",
      "Predict: -1\n",
      "Text: 我国又一个新冠病毒疫苗获批紧急使用。\n",
      "Predict: 0\n",
      "Text: 我们在一起，打赢这场仗，抗击新馆疫情，我们在行动！\n",
      "Predict: 1\n"
     ]
    }
   ],
   "source": [
    "# 展示预测结果\n",
    "for text, label in zip(predict_sentences, predict_labels):\n",
    "    print(f'Text: {text}\\nPredict: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型优化\n",
    "### 5.1 TextRNN\n",
    "RNN/LSTM 相对CNN更能捕捉序列信息，在短文本分类领域更适合\n",
    "\n",
    "![jupyter](./imgs/textrnn.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         630800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               731136    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,427,987\n",
      "Trainable params: 1,427,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM的维度\n",
    "LSTM_DIM = 256\n",
    "# 全连接层大小\n",
    "DENSE_DIM = 128\n",
    "\n",
    "# 通过Sequential方式定义TextRNN model\n",
    "# 其他层都与TextCNN一致\n",
    "# 将特征抽取层替换为BiLSTM\n",
    "text_rnn_model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=VOCAB_SIZE,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        # embeddings_initializer=tf.keras.initializers.Constant(embeddings),\n",
    "        trainable=True,\n",
    "        mask_zero=True\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "    # # 若两层BiLSTM, 第一层应return_sequences，然后继续接一层\n",
    "    # tf.keras.layers.Bidirectional(\n",
    "    #     tf.keras.layers.LSTM(LSTM_DIM * 2,  return_sequences=True)\n",
    "    # ),\n",
    "    # 加一层双向LSTM进行特征抽取\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(LSTM_DIM)\n",
    "    ),\n",
    "    tf.keras.layers.Dense(DENSE_DIM, activation='relu'),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "    tf.keras.layers.Dense(CLASS_NUM, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 上采样与下采样\n",
    "解决数据不平衡问题，可对数据比较多的标签进行下采样，对数据较少的标签进行上采样，达到数据集标签分布的平衡   \n",
    "下面是如何通过Tf dataset的方式构造平衡的数据集   \n",
    "在前面的分析中各标签数据分布为: [17.96, 56.83, 25.21]   \n",
    "这里构造一个相对平衡的数据集，设置各标签数据分布为 [0.3, 0.4, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1, 2]\n",
    "# 对[0, 1, 2]标签的数据不同的采样权重，强行定义采样\n",
    "balance_weights = [0.3, 0.4, 0.3]\n",
    "dataset_each_label = []\n",
    "\n",
    "for current_label in labels:\n",
    "    # 将训练集数据取消batch，选出对应标签的数据集，\n",
    "    # 然后设置repeat，则可有放回的采样，以实现上采样\n",
    "    current_label_dataset = train_dataset.unbatch().filter(\n",
    "        lambda example, label: tf.argmax(label) == current_label).repeat()\n",
    "    dataset_each_label.append(current_label_dataset)\n",
    "\n",
    "# 通过相对平衡的采样权重，构造相对平衡的数据集\n",
    "balanced_train_dataset = tf.data.experimental.sample_from_datasets(\n",
    "    dataset_each_label, weights=balance_weights)\n",
    "balanced_train_dataset = balanced_train_dataset.shuffle(BUFFER_SIZE)\\\n",
    "    .batch(BATCH_SIZE).prefetch(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [[ 201  363    3   46  149  712   14   16   38   86  668  253   92  234\n",
      "   332  124    9  729   92   11   38   86   43   44   14   16    3  109\n",
      "     2   79   91    4   83   66  110   36   37   66  110  167  103   66\n",
      "   110   17   27    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   8 2700    8 2700    8  272 2169  402   15    7 2067    7 2446    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [1740  621  231    8    5  120  213  331  117  117  117  117  117  117\n",
      "   117  117  117   10   22   58  247  238  131  433  177  162  162   57\n",
      "   247  247  445  976  939  964   58  247  238  131  433  177  162  162\n",
      "    57  247  247  157  649  149 2584  113   50   60   10   22    9  403\n",
      "   402   46   52    7  476  106   10  295   52    7  476  343 1188  594\n",
      "   259   51  295  326  130  214  763   55  184    2  454  925   70    7\n",
      "  1385  664  295  610   52  213   21   69  445  976  939  964   58    7\n",
      "   281  868  699  780  302  724 1013 1375   28 1684  449  991    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "\n",
      "labels:  [[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for example, label in balanced_train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 302s 15ms/step - loss: 0.1734 - accuracy: 0.7266 - val_loss: 0.8885 - val_accuracy: 0.6208\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 301s 15ms/step - loss: 0.1254 - accuracy: 0.7945 - val_loss: 0.9469 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 301s 15ms/step - loss: 0.1090 - accuracy: 0.8211 - val_loss: 1.0324 - val_accuracy: 0.6432\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 301s 15ms/step - loss: 0.0998 - accuracy: 0.8370 - val_loss: 1.0880 - val_accuracy: 0.6570\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 301s 15ms/step - loss: 0.0929 - accuracy: 0.8490 - val_loss: 1.1518 - val_accuracy: 0.6624\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 302s 15ms/step - loss: 0.0878 - accuracy: 0.8581 - val_loss: 1.1482 - val_accuracy: 0.6742\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 302s 15ms/step - loss: 0.0833 - accuracy: 0.8668 - val_loss: 1.1517 - val_accuracy: 0.6722\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 286s 14ms/step - loss: 0.0800 - accuracy: 0.8729 - val_loss: 1.2663 - val_accuracy: 0.6816\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 282s 14ms/step - loss: 0.0774 - accuracy: 0.8776 - val_loss: 1.2383 - val_accuracy: 0.6794\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 282s 14ms/step - loss: 0.0748 - accuracy: 0.8826 - val_loss: 1.2119 - val_accuracy: 0.6846\n"
     ]
    }
   ],
   "source": [
    "text_cnn_model_new = build_text_cnn_model()\n",
    "text_cnn_model_new.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']  # 使用accuracy进行评价\n",
    ")\n",
    "\n",
    "# 由于采样后构造的数据集是无限的，所以模型训练的方式需要做一些改变\n",
    "# 需要指定每个epoch跑多少个step，因为每个step随机从数据集中采样相对平衡的数据集\n",
    "history = text_cnn_model_new.fit(\n",
    "    balanced_train_dataset,  # 指定平衡后的训练数据集\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[callback],\n",
    "    validation_data=val_dataset,\n",
    "    class_weight=class_weight,\n",
    "    steps_per_epoch=20000,  # 指定每个epoch跑多少step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.78      0.60      1796\n",
      "           1       0.83      0.60      0.70      5651\n",
      "           2       0.63      0.74      0.68      2551\n",
      "\n",
      "    accuracy                           0.67      9998\n",
      "   macro avg       0.65      0.71      0.66      9998\n",
      "weighted avg       0.72      0.67      0.68      9998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看新数据集的模型结果\n",
    "predictions = text_cnn_model.predict(test_dataset)\n",
    "preds = np.argmax(predictions, axis=-1)\n",
    "result = classification_report(test_label, preds)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Focal Loss\n",
    "Focal Loss 论文详解： https://zhuanlan.zhihu.com/p/49981234  \n",
    "1. 交叉熵损失函数的计算，也就是各个样本的权重是一样，没有区分不同类别的样本。   \n",
    "2. 通过对不同类别样本的损失进行加权，解决一部分的数据不平衡问题。\n",
    "3. 2中的方案可以控制正负样本的权重，但是没法控制容易分类和难分类样本的权重，于是就有了focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "loss = tfa.losses.SigmoidFocalCrossEntropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据不平衡在TF中解决方案总结\n",
    "\n",
    "1. class_weight: 不同类别样本重要程度加权  \n",
    "2. balanced train dataset: 通过不同采样，构造相对平衡的数据集\n",
    "3. Focal Loss：一般类别分布较多的样本较好分类，通过对容易和难分类的样本进行加权，重点关注难分类样本\n",
    "\n",
    "3种解决方案，也可以互相组合，最后通过消融实验验证那种效果最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b35e09b3",
   "language": "python",
   "display_name": "PyCharm (Chapter.4)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}